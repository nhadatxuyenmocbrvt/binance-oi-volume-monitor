import os
import json
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
from config.settings import setup_logging, SYMBOLS
from data_analyzer.metrics import OptimizedOIVolumeMetrics

logger = setup_logging(__name__, 'report_generator.log')

# Th√™m NumpyEncoder ƒë·ªÉ x·ª≠ l√Ω c√°c ki·ªÉu d·ªØ li·ªáu NumPy
class NumpyEncoder(json.JSONEncoder):
    """JSON Encoder t√πy ch·ªânh ƒë·ªÉ x·ª≠ l√Ω c√°c ki·ªÉu d·ªØ li·ªáu NumPy"""
    def default(self, obj):
        if isinstance(obj, np.integer):
            return int(obj)
        elif isinstance(obj, np.floating):
            return float(obj)
        elif isinstance(obj, np.ndarray):
            return obj.tolist()
        elif isinstance(obj, np.bool_):
            return bool(obj)
        return super(NumpyEncoder, self).default(obj)

# H√†m ti·ªán √≠ch ƒë·ªÉ chuy·ªÉn ƒë·ªïi d·ªØ li·ªáu NumPy
def convert_numpy_types(obj):
    """Chuy·ªÉn ƒë·ªïi c√°c ki·ªÉu d·ªØ li·ªáu NumPy th√†nh ki·ªÉu Python ti√™u chu·∫©n"""
    if isinstance(obj, dict):
        return {k: convert_numpy_types(v) for k, v in obj.items()}
    elif isinstance(obj, list):
        return [convert_numpy_types(item) for item in obj]
    elif isinstance(obj, np.integer):
        return int(obj)
    elif isinstance(obj, np.floating):
        return float(obj)
    elif isinstance(obj, np.ndarray):
        return obj.tolist()
    elif isinstance(obj, np.bool_):
        return bool(obj)
    elif pd.isna(obj):  # X·ª≠ l√Ω gi√° tr·ªã NaN, NaT
        return None
    else:
        return obj

class OptimizedReportGenerator:
    """
    T·∫°o b√°o c√°o t·ªëi ∆∞u cho OI & Volume
    Focus: Tracking 24h (hourly) + 30d (daily)
    """
    
    def __init__(self, db):
        self.db = db
        self.metrics = OptimizedOIVolumeMetrics()
        logger.info("üîß Kh·ªüi t·∫°o OptimizedReportGenerator - Focus OI & Volume")
    
    def generate_daily_summary(self):
        """
        T·∫°o b√°o c√°o t·ªïng h·ª£p h√†ng ng√†y t·ªëi ∆∞u
        """
        try:
            logger.info("üìä T·∫°o b√°o c√°o t·ªïng h·ª£p h√†ng ng√†y")
            
            summary = {
                'timestamp': datetime.now().isoformat(),
                'report_type': 'daily_oi_volume_summary',
                'symbols': {},
                'overall_metrics': {
                    'total_symbols': len(SYMBOLS),
                    'bullish_count': 0,
                    'bearish_count': 0,
                    'neutral_count': 0
                },
                'anomalies_summary': {},
                'data_quality': {}
            }
            
            # T·∫°o b√°o c√°o cho t·ª´ng symbol
            for symbol in SYMBOLS:
                try:
                    symbol_report = self._generate_symbol_report(symbol)
                    summary['symbols'][symbol] = symbol_report
                    
                    # C·∫≠p nh·∫≠t overall metrics
                    sentiment = symbol_report.get('overall_sentiment', 'neutral')
                    if 'bullish' in sentiment:
                        summary['overall_metrics']['bullish_count'] += 1
                    elif 'bearish' in sentiment:
                        summary['overall_metrics']['bearish_count'] += 1
                    else:
                        summary['overall_metrics']['neutral_count'] += 1
                        
                except Exception as e:
                    logger.error(f"‚ùå L·ªói khi t·∫°o b√°o c√°o cho {symbol}: {str(e)}")
                    summary['symbols'][symbol] = self._get_empty_symbol_report()
            
            # T·∫°o anomalies summary
            summary['anomalies_summary'] = self._generate_anomalies_summary()
            
            # L∆∞u b√°o c√°o
            self._save_report(summary, 'daily_summary.json')
            
            logger.info("‚úÖ Ho√†n th√†nh b√°o c√°o t·ªïng h·ª£p h√†ng ng√†y")
            return summary
            
        except Exception as e:
            logger.error(f"‚ùå L·ªói khi t·∫°o b√°o c√°o t·ªïng h·ª£p: {str(e)}")
            return {}
    
    def generate_24h_data(self):
        """
        T·∫°o d·ªØ li·ªáu tracking 24h cho web interface
        """
        try:
            logger.info("üìà T·∫°o d·ªØ li·ªáu tracking 24h")
            
            tracking_data = {
                'timestamp': datetime.now().isoformat(),
                'data_type': '24h_hourly_tracking',
                'symbols': {}
            }
            
            for symbol in SYMBOLS:
                try:
                    # L·∫•y d·ªØ li·ªáu tracking 24h
                    tracking_df = self.db.get_24h_tracking_data(symbol)
                    
                    if not tracking_df.empty:
                        # T√≠nh to√°n metrics
                        oi_metrics = self.metrics.calculate_hourly_oi_metrics(tracking_df)
                        volume_metrics = self.metrics.calculate_hourly_volume_metrics(tracking_df)
                        correlation = self.metrics.calculate_oi_volume_correlation(tracking_df, '24h')
                        
                        # Chu·∫©n b·ªã d·ªØ li·ªáu cho chart
                        chart_data = []
                        for _, row in tracking_df.iterrows():
                            chart_data.append({
                                'timestamp': row['hour_timestamp'].isoformat() if hasattr(row['hour_timestamp'], 'isoformat') else str(row['hour_timestamp']),
                                'hour': row['hour_timestamp'].strftime('%H:00') if hasattr(row['hour_timestamp'], 'strftime') else str(row['hour_timestamp']),
                                'oi': float(row['open_interest']),
                                'volume': float(row['volume']),
                                'price': float(row['price']),
                                'oi_change_1h': float(row.get('oi_change_1h', 0)),
                                'volume_change_1h': float(row.get('volume_change_1h', 0)),
                                'price_change_1h': float(row.get('price_change_1h', 0))
                            })
                        
                        # T·∫°o d·ªØ li·ªáu symbol
                        tracking_data['symbols'][symbol] = {
                            'oi_metrics': oi_metrics,
                            'volume_metrics': volume_metrics,
                            'correlation': correlation,
                            'chart_data': chart_data,
                            'data_points': len(chart_data),
                            'last_update': tracking_df['hour_timestamp'].iloc[-1].isoformat() if not tracking_df.empty else None
                        }
                        
                    else:
                        tracking_data['symbols'][symbol] = self._get_empty_24h_data()
                        
                except Exception as e:
                    logger.error(f"‚ùå L·ªói khi t·∫°o tracking 24h cho {symbol}: {str(e)}")
                    tracking_data['symbols'][symbol] = self._get_empty_24h_data()
            
            # L∆∞u d·ªØ li·ªáu tracking 24h
            self._save_report(tracking_data, '24h_tracking.json')
            
            logger.info("‚úÖ Ho√†n th√†nh t·∫°o d·ªØ li·ªáu tracking 24h")
            return tracking_data
            
        except Exception as e:
            logger.error(f"‚ùå L·ªói khi t·∫°o d·ªØ li·ªáu tracking 24h: {str(e)}")
            return {}
    
    def generate_30d_data(self):
        """
        T·∫°o d·ªØ li·ªáu tracking 30d cho web interface
        """
        try:
            logger.info("üìä T·∫°o d·ªØ li·ªáu tracking 30d")
            
            tracking_data = {
                'timestamp': datetime.now().isoformat(),
                'data_type': '30d_daily_tracking',
                'symbols': {}
            }
            
            for symbol in SYMBOLS:
                try:
                    # L·∫•y d·ªØ li·ªáu OI v√† klines 30 ng√†y
                    oi_df = self.db.get_open_interest(symbol, limit=720)  # 30 days * 24 hours
                    klines_df = self.db.get_klines(symbol, '1d', limit=30)
                    
                    if not oi_df.empty and not klines_df.empty:
                        # T√≠nh to√°n metrics
                        oi_metrics = self.metrics.calculate_daily_oi_metrics(oi_df)
                        volume_metrics = self.metrics.calculate_daily_volume_metrics(klines_df)
                        
                        # Merge d·ªØ li·ªáu cho correlation
                        merged_df = self._merge_daily_data(oi_df, klines_df)
                        correlation = self.metrics.calculate_oi_volume_correlation(merged_df, '30d')
                        
                        # Chu·∫©n b·ªã d·ªØ li·ªáu chart (daily aggregated)
                        chart_data = self._prepare_30d_chart_data(oi_df, klines_df)
                        
                        tracking_data['symbols'][symbol] = {
                            'oi_metrics': oi_metrics,
                            'volume_metrics': volume_metrics,
                            'correlation': correlation,
                            'chart_data': chart_data,
                            'data_points': len(chart_data),
                            'last_update': datetime.now().isoformat()
                        }
                        
                    else:
                        tracking_data['symbols'][symbol] = self._get_empty_30d_data()
                        
                except Exception as e:
                    logger.error(f"‚ùå L·ªói khi t·∫°o tracking 30d cho {symbol}: {str(e)}")
                    tracking_data['symbols'][symbol] = self._get_empty_30d_data()
            
            # L∆∞u d·ªØ li·ªáu tracking 30d
            self._save_report(tracking_data, '30d_tracking.json')
            
            logger.info("‚úÖ Ho√†n th√†nh t·∫°o d·ªØ li·ªáu tracking 30d")
            return tracking_data
            
        except Exception as e:
            logger.error(f"‚ùå L·ªói khi t·∫°o d·ªØ li·ªáu tracking 30d: {str(e)}")
            return {}
    
    def generate_web_data(self):
        """
        T·∫°o t·∫•t c·∫£ d·ªØ li·ªáu c·∫ßn thi·∫øt cho web interface
        """
        try:
            logger.info("üåê T·∫°o d·ªØ li·ªáu cho web interface")
            
            # T·∫°o d·ªØ li·ªáu 24h v√† 30d
            data_24h = self.generate_24h_data()
            data_30d = self.generate_30d_data()
            daily_summary = self.generate_daily_summary()
            
            # T·∫°o index data cho web
            web_data = {
                'last_update': datetime.now().isoformat(),
                'symbols': SYMBOLS,
                'data_24h': data_24h,
                'data_30d': data_30d,
                'summary': daily_summary,
                'status': 'active'
            }
            
            # L∆∞u index data
            self._save_report(web_data, 'web_index.json')
            
            logger.info("‚úÖ Ho√†n th√†nh t·∫°o d·ªØ li·ªáu cho web")
            return web_data
            
        except Exception as e:
            logger.error(f"‚ùå L·ªói khi t·∫°o d·ªØ li·ªáu web: {str(e)}")
            return {}
    
    def _generate_symbol_report(self, symbol):
        """
        T·∫°o b√°o c√°o chi ti·∫øt cho m·ªôt symbol
        """
        try:
            report = {
                'symbol': symbol,
                'timestamp': datetime.now().isoformat()
            }
            
            # L·∫•y d·ªØ li·ªáu tracking 24h
            tracking_df = self.db.get_24h_tracking_data(symbol)
            if not tracking_df.empty:
                oi_metrics_24h = self.metrics.calculate_hourly_oi_metrics(tracking_df)
                volume_metrics_24h = self.metrics.calculate_hourly_volume_metrics(tracking_df)
                
                report['24h_metrics'] = {
                    'oi': oi_metrics_24h,
                    'volume': volume_metrics_24h
                }
            else:
                report['24h_metrics'] = {
                    'oi': self.metrics._get_empty_oi_metrics(),
                    'volume': self.metrics._get_empty_volume_metrics()
                }
            
            # L·∫•y d·ªØ li·ªáu 30d
            oi_df = self.db.get_open_interest(symbol, limit=720)
            klines_df = self.db.get_klines(symbol, '1d', limit=30)
            
            if not oi_df.empty and not klines_df.empty:
                oi_metrics_30d = self.metrics.calculate_daily_oi_metrics(oi_df)
                volume_metrics_30d = self.metrics.calculate_daily_volume_metrics(klines_df)
                
                report['30d_metrics'] = {
                    'oi': oi_metrics_30d,
                    'volume': volume_metrics_30d
                }
            else:
                report['30d_metrics'] = {
                    'oi': self.metrics._get_empty_oi_metrics_30d(),
                    'volume': self.metrics._get_empty_volume_metrics_30d()
                }
            
            # T√≠nh overall sentiment
            report['overall_sentiment'] = self._determine_overall_sentiment(
                report['24h_metrics'],
                report['30d_metrics']
            )
            
            # Th√™m summary metrics
            report['price_change'] = report['24h_metrics']['oi'].get('oi_change_24h', 0)  # T·∫°m th·ªùi d√πng OI change
            report['sentiment'] = report['overall_sentiment']
            
            return report
            
        except Exception as e:
            logger.error(f"‚ùå L·ªói khi t·∫°o b√°o c√°o symbol {symbol}: {str(e)}")
            return self._get_empty_symbol_report()
    
    def _generate_anomalies_summary(self):
        """
        T·∫°o t√≥m t·∫Øt anomalies g·∫ßn ƒë√¢y
        """
        try:
            # L·∫•y anomalies 24h g·∫ßn nh·∫•t
            anomalies_df = self.db.get_anomalies(limit=100)
            
            if anomalies_df.empty:
                return {
                    'total': 0,
                    'by_symbol': {},
                    'by_type': {},
                    'recent_24h': 0
                }
            
            # L·ªçc anomalies 24h g·∫ßn nh·∫•t
            cutoff_time = datetime.now() - timedelta(hours=24)
            recent_anomalies = anomalies_df[anomalies_df['timestamp'] >= cutoff_time]
            
            summary = {
                'total': len(anomalies_df),
                'recent_24h': len(recent_anomalies),
                'by_symbol': recent_anomalies['symbol'].value_counts().to_dict() if not recent_anomalies.empty else {},
                'by_type': recent_anomalies['data_type'].value_counts().to_dict() if not recent_anomalies.empty else {},
                'timestamp': datetime.now().isoformat()
            }
            
            return summary
            
        except Exception as e:
            logger.error(f"‚ùå L·ªói khi t·∫°o anomalies summary: {str(e)}")
            return {
                'total': 0,
                'by_symbol': {},
                'by_type': {},
                'recent_24h': 0
            }
    
    def _merge_daily_data(self, oi_df, klines_df):
        """
        Merge d·ªØ li·ªáu OI v√† klines theo ng√†y
        """
        try:
            # Group OI data by date
            oi_df['date'] = pd.to_datetime(oi_df['timestamp']).dt.date
            oi_daily = oi_df.groupby('date')['open_interest'].mean().reset_index()
            
            # Group klines data by date
            klines_df['date'] = pd.to_datetime(klines_df['open_time']).dt.date
            volume_daily = klines_df.groupby('date')[['volume', 'close']].agg({
                'volume': 'sum',
                'close': 'last'
            }).reset_index()
            
            # Merge
            merged = pd.merge(oi_daily, volume_daily, on='date', how='inner')
            merged['timestamp'] = pd.to_datetime(merged['date'])
            
            return merged
            
        except Exception as e:
            logger.error(f"‚ùå L·ªói khi merge daily data: {str(e)}")
            return pd.DataFrame()
    
    def _prepare_30d_chart_data(self, oi_df, klines_df):
        """
        Chu·∫©n b·ªã d·ªØ li·ªáu chart cho 30 ng√†y
        """
        try:
            merged_df = self._merge_daily_data(oi_df, klines_df)
            
            if merged_df.empty:
                return []
            
            # L·∫•y 30 ng√†y g·∫ßn nh·∫•t
            merged_df = merged_df.sort_values('date').tail(30)
            
            chart_data = []
            for _, row in merged_df.iterrows():
                chart_data.append({
                    'date': row['date'].isoformat(),
                    'oi': float(row['open_interest']),
                    'volume': float(row['volume']),
                    'price': float(row['close'])
                })
            
            return chart_data
            
        except Exception as e:
            logger.error(f"‚ùå L·ªói khi chu·∫©n b·ªã 30d chart data: {str(e)}")
            return []
    
    def _determine_overall_sentiment(self, metrics_24h, metrics_30d):
        """
        X√°c ƒë·ªãnh sentiment t·ªïng th·ªÉ
        """
        try:
            # L·∫•y thay ƒë·ªïi t·ª´ metrics
            oi_change_24h = metrics_24h['oi'].get('oi_change_24h', 0)
            volume_change_24h = metrics_24h['volume'].get('volume_change_24h', 0)
            oi_change_30d = metrics_30d['oi'].get('oi_change_30d', 0)
            volume_change_30d = metrics_30d['volume'].get('volume_change_30d', 0)
            
            # Logic sentiment ƒë∆°n gi·∫£n
            if oi_change_24h > 5 and volume_change_24h > 10:
                return 'strong_bullish'
            elif oi_change_24h > 1 and volume_change_24h > 5:
                return 'bullish'
            elif oi_change_24h < -5 and volume_change_24h < -10:
                return 'strong_bearish'
            elif oi_change_24h < -1 and volume_change_24h < -5:
                return 'bearish'
            elif abs(oi_change_30d) > 20 or abs(volume_change_30d) > 30:
                return 'volatile'
            else:
                return 'neutral'
                
        except Exception as e:
            logger.error(f"‚ùå L·ªói khi x√°c ƒë·ªãnh sentiment: {str(e)}")
            return 'neutral'
    
    def _save_report(self, data, filename):
        """
        L∆∞u b√°o c√°o v√†o file JSON
        """
        try:
            # ƒê·∫£m b·∫£o th∆∞ m·ª•c t·ªìn t·∫°i
            os.makedirs('data/reports', exist_ok=True)
            os.makedirs('data/json', exist_ok=True)
            os.makedirs('docs/assets/data', exist_ok=True)  # Th√™m th∆∞ m·ª•c cho GitHub Pages
            
            # Chuy·ªÉn ƒë·ªïi d·ªØ li·ªáu NumPy tr∆∞·ªõc khi l∆∞u
            converted_data = convert_numpy_types(data)
            
            # L∆∞u v√†o th∆∞ m·ª•c reports
            reports_path = f'data/reports/{filename}'
            with open(reports_path, 'w', encoding='utf-8') as f:
                json.dump(converted_data, f, ensure_ascii=False, indent=2, cls=NumpyEncoder)
            
            # L∆∞u v√†o th∆∞ m·ª•c json cho web
            json_path = f'data/json/{filename}'
            with open(json_path, 'w', encoding='utf-8') as f:
                json.dump(converted_data, f, ensure_ascii=False, indent=2, cls=NumpyEncoder)
                
            # L∆∞u v√†o th∆∞ m·ª•c GitHub Pages
            github_pages_path = f'docs/assets/data/{filename}'
            with open(github_pages_path, 'w', encoding='utf-8') as f:
                json.dump(converted_data, f, ensure_ascii=False, indent=2, cls=NumpyEncoder)
            
            logger.info(f"üíæ ƒê√£ l∆∞u b√°o c√°o: {filename}")
            
        except Exception as e:
            logger.error(f"‚ùå L·ªói khi l∆∞u b√°o c√°o {filename}: {str(e)}")
    
    # Helper methods ƒë·ªÉ tr·∫£ v·ªÅ d·ªØ li·ªáu tr·ªëng
    def _get_empty_symbol_report(self):
        return {
            'symbol': '',
            'timestamp': datetime.now().isoformat(),
            '24h_metrics': {
                'oi': self.metrics._get_empty_oi_metrics(),
                'volume': self.metrics._get_empty_volume_metrics()
            },
            '30d_metrics': {
                'oi': self.metrics._get_empty_oi_metrics_30d(),
                'volume': self.metrics._get_empty_volume_metrics_30d()
            },
            'overall_sentiment': 'neutral',
            'price_change': 0,
            'sentiment': 'neutral'
        }
    
    def _get_empty_24h_data(self):
        return {
            'oi_metrics': self.metrics._get_empty_oi_metrics(),
            'volume_metrics': self.metrics._get_empty_volume_metrics(),
            'correlation': {'correlation': 0, 'correlation_strength': 'no_data'},
            'chart_data': [],
            'data_points': 0,
            'last_update': None
        }
    
    def _get_empty_30d_data(self):
        return {
            'oi_metrics': self.metrics._get_empty_oi_metrics_30d(),
            'volume_metrics': self.metrics._get_empty_volume_metrics_30d(),
            'correlation': {'correlation': 0, 'correlation_strength': 'no_data'},
            'chart_data': [],
            'data_points': 0,
            'last_update': None
        }

# Backward compatibility alias
ReportGenerator = OptimizedReportGenerator