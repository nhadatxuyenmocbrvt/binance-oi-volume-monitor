import time
import hmac
import hashlib
import requests
import pandas as pd
from urllib.parse import urlencode
from datetime import datetime, timedelta
from config.settings import BINANCE_API_KEY, BINANCE_API_SECRET, setup_logging

logger = setup_logging(__name__, 'binance_api.log')

class OptimizedBinanceAPI:
    """
    Binance API t·ªëi ∆∞u cho vi·ªác thu th·∫≠p OI & Volume
    Focus: 24h tracking (hourly) + 30d tracking (daily)
    FIX: StartTime validation errors
    """
    
    def __init__(self):
        self.base_url = 'https://fapi.binance.com'
        self.data_url = 'https://fapi.binance.com'
        self.api_key = BINANCE_API_KEY
        self.api_secret = BINANCE_API_SECRET
        
        # Rate limiting settings
        self.request_delay = 0.2
        self.max_retries = 3
        self.retry_delay = 1
        
        # Cache server time
        self._server_time_cache = None
        self._server_time_cache_expires = 0
        
        # Cache symbol info ƒë·ªÉ validate startTime
        self._symbol_info_cache = {}
        
        logger.info("üîß Kh·ªüi t·∫°o OptimizedBinanceAPI - Focus OI & Volume [FIXED]")
        
    def _generate_signature(self, params):
        """T·∫°o ch·ªØ k√Ω HMAC-SHA256 cho request"""
        query_string = urlencode(params, safe='')
        signature = hmac.new(
            self.api_secret.encode('utf-8'),
            query_string.encode('utf-8'),
            hashlib.sha256
        ).hexdigest()
        return signature
    
    def _make_request(self, endpoint, method='GET', params=None, signed=False, base_url=None):
        """Th·ª±c hi·ªán request ƒë·∫øn Binance API v·ªõi retry v√† rate limiting"""
        if base_url is None:
            base_url = self.base_url
            
        url = f"{base_url}{endpoint}"
        headers = {
            'X-MBX-APIKEY': self.api_key,
            'Content-Type': 'application/json'
        }
        
        if params is None:
            params = {}
            
        if signed:
            params['timestamp'] = int(time.time() * 1000)
            params['signature'] = self._generate_signature(params)
        
        # Retry logic v·ªõi exponential backoff
        for attempt in range(self.max_retries):
            try:
                time.sleep(self.request_delay)
                
                if method == 'GET':
                    response = requests.get(url, headers=headers, params=params, timeout=30)
                elif method == 'POST':
                    response = requests.post(url, headers=headers, json=params, timeout=30)
                else:
                    logger.error(f"‚ùå Ph∆∞∆°ng th·ª©c kh√¥ng ƒë∆∞·ª£c h·ªó tr·ª£: {method}")
                    return None
                
                if response.status_code == 200:
                    return response.json()
                elif response.status_code == 429:  # Rate limit
                    wait_time = (2 ** attempt) * self.retry_delay
                    logger.warning(f"‚ö†Ô∏è Rate limit hit, waiting {wait_time}s (attempt {attempt + 1}/{self.max_retries})")
                    time.sleep(wait_time)
                    continue
                elif response.status_code == 418:  # IP banned
                    logger.error(f"üö´ IP banned temporarily")
                    time.sleep(60)
                    continue
                elif response.status_code == 400:  # Bad request - log details
                    error_msg = response.text
                    logger.error(f"‚ùå Bad Request (400): {error_msg}")
                    return None
                else:
                    logger.error(f"‚ùå API Error: {response.status_code} - {response.text}")
                    if attempt == self.max_retries - 1:
                        return None
                    time.sleep((2 ** attempt) * self.retry_delay)
                    
            except requests.exceptions.Timeout:
                logger.warning(f"‚è∞ Request timeout (attempt {attempt + 1}/{self.max_retries})")
                if attempt == self.max_retries - 1:
                    return None
                time.sleep((2 ** attempt) * self.retry_delay)
                
            except requests.exceptions.ConnectionError:
                logger.warning(f"üîå Connection error (attempt {attempt + 1}/{self.max_retries})")
                if attempt == self.max_retries - 1:
                    return None
                time.sleep((2 ** attempt) * self.retry_delay)
                
            except Exception as e:
                logger.error(f"‚ùå Unexpected error: {str(e)}")
                if attempt == self.max_retries - 1:
                    return None
                time.sleep((2 ** attempt) * self.retry_delay)
        
        return None
    
    def get_server_time(self, force_refresh=False):
        """L·∫•y th·ªùi gian ch√≠nh x√°c t·ª´ m√°y ch·ªß Binance v·ªõi caching"""
        current_time = time.time() * 1000
        
        if not force_refresh and self._server_time_cache and current_time < self._server_time_cache_expires:
            time_diff = current_time - (self._server_time_cache_expires - 300000)
            return int(self._server_time_cache + time_diff)
        
        endpoint = '/fapi/v1/time'
        result = self._make_request(endpoint)
        
        if result and 'serverTime' in result:
            self._server_time_cache = result['serverTime']
            self._server_time_cache_expires = current_time + 300000
            logger.info(f"üïí Server time updated: {datetime.fromtimestamp(result['serverTime']/1000)}")
            return result['serverTime']
        else:
            safe_time = int(current_time - 60000)
            logger.warning(f"‚ö†Ô∏è Cannot get server time, using safe time: {datetime.fromtimestamp(safe_time/1000)}")
            return safe_time
    
    def get_symbol_info(self, symbol):
        """
        L·∫•y th√¥ng tin symbol ƒë·ªÉ validate startTime - FIX M·ªöI
        """
        if symbol in self._symbol_info_cache:
            return self._symbol_info_cache[symbol]
        
        try:
            exchange_info = self.get_exchange_info()
            if exchange_info and 'symbols' in exchange_info:
                for sym_info in exchange_info['symbols']:
                    if sym_info['symbol'] == symbol:
                        info = {
                            'onboardDate': sym_info.get('onboardDate', 0),
                            'status': sym_info.get('status', 'TRADING')
                        }
                        self._symbol_info_cache[symbol] = info
                        logger.info(f"üìã Symbol {symbol} info cached: onboard={datetime.fromtimestamp(info['onboardDate']/1000) if info['onboardDate'] else 'Unknown'}")
                        return info
            
            # Fallback n·∫øu kh√¥ng t√¨m th·∫•y
            fallback_info = {'onboardDate': 0, 'status': 'TRADING'}
            self._symbol_info_cache[symbol] = fallback_info
            return fallback_info
            
        except Exception as e:
            logger.error(f"‚ùå Error getting symbol info for {symbol}: {str(e)}")
            fallback_info = {'onboardDate': 0, 'status': 'TRADING'}
            self._symbol_info_cache[symbol] = fallback_info
            return fallback_info
    
    def get_exchange_info(self):
        """L·∫•y th√¥ng tin v·ªÅ c√°c c·∫∑p giao d·ªãch"""
        endpoint = '/fapi/v1/exchangeInfo'
        return self._make_request(endpoint)
    
    def _validate_start_time(self, symbol, start_time):
        """
        Validate v√† adjust startTime ƒë·ªÉ tr√°nh l·ªói invalid - FIX M·ªöI
        """
        if not start_time:
            return start_time
        
        server_time = self.get_server_time()
        
        # Convert to timestamp if needed
        if isinstance(start_time, datetime):
            start_time = int(start_time.timestamp() * 1000)
        
        # Ki·ªÉm tra n·∫øu trong t∆∞∆°ng lai
        if start_time > server_time:
            logger.warning(f"‚ö†Ô∏è {symbol}: startTime in future, adjusting...")
            start_time = server_time - (24 * 60 * 60 * 1000)
        
        # L·∫•y th√¥ng tin symbol ƒë·ªÉ ki·ªÉm tra onboard date
        symbol_info = self.get_symbol_info(symbol)
        onboard_date = symbol_info.get('onboardDate', 0)
        
        if onboard_date > 0:
            # ƒê·∫£m b·∫£o startTime kh√¥ng tr∆∞·ªõc onboard date
            if start_time < onboard_date:
                logger.warning(f"‚ö†Ô∏è {symbol}: startTime before onboard date, adjusting from {datetime.fromtimestamp(start_time/1000)} to {datetime.fromtimestamp(onboard_date/1000)}")
                start_time = onboard_date + (60 * 60 * 1000)  # Th√™m 1 gi·ªù buffer
        
        # Gi·ªõi h·∫°n t·ªëi ƒëa 30 ng√†y
        max_lookback = 30 * 24 * 60 * 60 * 1000
        min_allowed_time = server_time - max_lookback
        
        if start_time < min_allowed_time:
            logger.warning(f"‚ö†Ô∏è {symbol}: startTime too far back, adjusting to 30 days limit")
            start_time = min_allowed_time
        
        return start_time
    
    def get_klines(self, symbol, interval, start_time=None, end_time=None, limit=1000):
        """
        L·∫•y d·ªØ li·ªáu n·∫øn (klines) t·ªëi ∆∞u v·ªõi validation
        """
        endpoint = '/fapi/v1/klines'
        
        if not symbol or not interval:
            logger.error("‚ùå Symbol v√† interval kh√¥ng ƒë∆∞·ª£c ƒë·ªÉ tr·ªëng")
            return None
        
        server_time = self.get_server_time()
        
        # Validate v√† adjust timestamps
        if start_time:
            start_time = self._validate_start_time(symbol, start_time)
        
        if end_time:
            if isinstance(end_time, datetime):
                end_time = int(end_time.timestamp() * 1000)
            if end_time > server_time:
                end_time = server_time
        
        params = {
            'symbol': symbol,
            'interval': interval,
            'limit': min(limit, 1500)
        }
        
        if start_time:
            params['startTime'] = start_time
        if end_time:
            params['endTime'] = end_time
        
        logger.info(f"üìä Requesting klines for {symbol} {interval}: {datetime.fromtimestamp((start_time or 0)/1000)} - {datetime.fromtimestamp((end_time or server_time)/1000)}")
        
        data = self._make_request(endpoint, params=params)
        
        if data:
            df = self._process_klines_data(data)
            logger.info(f"‚úÖ Retrieved {len(df)} klines for {symbol} {interval}")
            return df
        
        logger.warning(f"‚ö†Ô∏è No klines data for {symbol} {interval}")
        return None
    
    def get_open_interest(self, symbol, period='1h', start_time=None, end_time=None, limit=500):
        """
        L·∫•y d·ªØ li·ªáu Open Interest t·ªëi ∆∞u v·ªõi validation - FIX START_TIME
        """
        endpoint = '/futures/data/openInterestHist'
        
        valid_periods = ['5m', '15m', '30m', '1h', '2h', '4h', '6h', '12h', '1d']
        if period not in valid_periods:
            logger.error(f"‚ùå Invalid period: {period}. Valid: {valid_periods}")
            return None
        
        server_time = self.get_server_time()
        
        # Validate start_time v·ªõi symbol-specific logic
        if start_time:
            original_start = start_time
            start_time = self._validate_start_time(symbol, start_time)
            
            # ƒê·∫∑c bi·ªát check cho OI data availability
            if start_time != original_start:
                logger.info(f"üîß {symbol} OI startTime adjusted: {datetime.fromtimestamp(original_start/1000 if isinstance(original_start, int) else original_start.timestamp())} ‚Üí {datetime.fromtimestamp(start_time/1000)}")
        
        if end_time:
            if isinstance(end_time, datetime):
                end_time = int(end_time.timestamp() * 1000)
            if end_time > server_time:
                end_time = server_time
        
        params = {
            'symbol': symbol,
            'period': period,
            'limit': min(limit, 500)
        }
        
        if start_time:
            params['startTime'] = start_time
        if end_time:
            params['endTime'] = end_time
        
        logger.info(f"üî¢ Requesting OI for {symbol} {period}: {datetime.fromtimestamp((start_time or 0)/1000)} - {datetime.fromtimestamp((end_time or server_time)/1000)}")
        
        data = self._make_request(endpoint, params=params)
        
        if data:
            df = self._process_oi_data(data)
            # Log m·ªôt m·∫´u gi√° tr·ªã ƒë·ªÉ debug
            if not df.empty:
                logger.info(f"üîç Sample OI data for {symbol}: OI={df['sumOpenInterest'].iloc[0]}, Value={df['sumOpenInterestValue'].iloc[0]}")
            logger.info(f"‚úÖ Retrieved {len(df)} OI points for {symbol} {period}")
            return df
        
        logger.warning(f"‚ö†Ô∏è No OI data for {symbol} {period}")
        return None
    
    def get_open_interest_chunked(self, symbol, period='1h', start_time=None, end_time=None, days_per_chunk=7):
        """
        L·∫•y d·ªØ li·ªáu OI theo chunks v·ªõi smart start_time validation
        """
        all_data = []
        
        if isinstance(start_time, datetime):
            start_time = int(start_time.timestamp() * 1000)
        if isinstance(end_time, datetime):
            end_time = int(end_time.timestamp() * 1000)
        
        if not end_time:
            end_time = self.get_server_time()
        
        # Validate start_time tr∆∞·ªõc khi chia chunks
        if start_time:
            start_time = self._validate_start_time(symbol, start_time)
        
        chunk_duration = days_per_chunk * 24 * 60 * 60 * 1000
        current_start = start_time
        chunk_count = 0
        max_chunks = 10  # Gi·ªõi h·∫°n s·ªë chunks ƒë·ªÉ tr√°nh v√≤ng l·∫∑p v√¥ t·∫≠n
        
        while current_start < end_time and chunk_count < max_chunks:
            current_end = min(current_start + chunk_duration, end_time)
            
            # Skip chunks that are too small
            if current_end - current_start < (60 * 60 * 1000):  # Less than 1 hour
                logger.info(f"‚è≠Ô∏è Skipping small chunk for {symbol}: {datetime.fromtimestamp(current_start/1000)}")
                break
            
            df = self.get_open_interest(symbol, period, current_start, current_end, 500)
            
            if df is not None and not df.empty:
                # Log ƒë·ªÉ debug gi√° tr·ªã OI
                logger.info(f"üîç OI value range for chunk {chunk_count+1}: {df['sumOpenInterest'].min()} - {df['sumOpenInterest'].max()}")
                logger.info(f"üîç OI value in USD range: {df['sumOpenInterestValue'].min()} - {df['sumOpenInterestValue'].max()}")
                
                all_data.append(df)
                logger.info(f"üìä OI Chunk {chunk_count + 1}: {len(df)} points from {datetime.fromtimestamp(current_start/1000)}")
            else:
                logger.warning(f"‚ö†Ô∏è Empty chunk for {symbol}: {datetime.fromtimestamp(current_start/1000)}")
            
            current_start = current_end + (60 * 60 * 1000)  # 1 hour overlap
            chunk_count += 1
            
            # Rate limiting between chunks
            time.sleep(1.0)
        
        if all_data:
            result = pd.concat(all_data, ignore_index=True).drop_duplicates(subset=['timestamp'])
            logger.info(f"‚úÖ Total {len(result)} OI points collected for {symbol} ({chunk_count} chunks)")
            
            # Log th√™m th√¥ng tin ƒë·ªÉ debug
            if not result.empty:
                logger.info(f"üìà Final OI data summary for {symbol}:")
                logger.info(f"   - OI range: {result['sumOpenInterest'].min()} - {result['sumOpenInterest'].max()}")
                logger.info(f"   - OI value range: {result['sumOpenInterestValue'].min()} - {result['sumOpenInterestValue'].max()}")
                logger.info(f"   - Date range: {result['timestamp'].min()} - {result['timestamp'].max()}")
            
            return result.sort_values('timestamp').reset_index(drop=True)
        
        logger.warning(f"‚ö†Ô∏è No OI data collected for {symbol}")
        return None
    
    def get_klines_chunked(self, symbol, interval, start_time, end_time, chunk_size=1000):
        """L·∫•y d·ªØ li·ªáu klines theo chunks v·ªõi validation"""
        all_data = []
        
        if isinstance(start_time, datetime):
            start_time = int(start_time.timestamp() * 1000)
        if isinstance(end_time, datetime):
            end_time = int(end_time.timestamp() * 1000)
        
        # Validate start_time
        start_time = self._validate_start_time(symbol, start_time)
        
        interval_ms = self._get_interval_milliseconds(interval)
        chunk_duration = chunk_size * interval_ms
        
        current_start = start_time
        
        while current_start < end_time:
            current_end = min(current_start + chunk_duration, end_time)
            
            df = self.get_klines(symbol, interval, current_start, current_end, chunk_size)
            
            if df is not None and not df.empty:
                all_data.append(df)
                logger.info(f"üìà Chunk: {len(df)} candles from {datetime.fromtimestamp(current_start/1000)}")
            
            current_start = current_end + interval_ms
            time.sleep(0.5)
        
        if all_data:
            result = pd.concat(all_data, ignore_index=True).drop_duplicates(subset=['open_time'])
            logger.info(f"‚úÖ Total {len(result)} klines collected for {symbol} {interval}")
            return result.sort_values('open_time').reset_index(drop=True)
        
        return None
    
    def get_open_interest_realtime(self, symbol):
        """L·∫•y d·ªØ li·ªáu Open Interest hi·ªán t·∫°i"""
        endpoint = '/fapi/v1/openInterest'
        params = {'symbol': symbol}
        
        data = self._make_request(endpoint, params=params)
        
        if data and 'openInterest' in data:
            # Chuy·ªÉn t·ª´ string sang float ƒë·ªÉ t√≠nh to√°n
            open_interest = float(data['openInterest'])
            logger.info(f"üìä Current OI for {symbol}: {open_interest}")
            
            # L·∫•y th√™m gi√° hi·ªán t·∫°i ƒë·ªÉ t√≠nh OI theo USDT
            ticker = self.get_ticker(symbol)
            if ticker and 'lastPrice' in ticker:
                price = float(ticker['lastPrice'])
                oi_value = open_interest * price
                logger.info(f"üí∞ Current OI Value (USDT) for {symbol}: {oi_value}")
                
                # Th√™m gi√° tr·ªã USDT v√†o k·∫øt qu·∫£
                data['openInterestValue'] = oi_value
                # Th√™m timestamp hi·ªán t·∫°i
                data['timestamp'] = datetime.now()
            
            return data
        
        logger.warning(f"‚ö†Ô∏è No current OI data for {symbol}")
        return None
    
    def get_ticker(self, symbol=None):
        """L·∫•y th√¥ng tin ticker 24h"""
        endpoint = '/fapi/v1/ticker/24hr'
        params = {}
        
        if symbol:
            params['symbol'] = symbol
        
        data = self._make_request(endpoint, params=params)
        
        if data:
            if symbol:
                logger.info(f"üìà Ticker for {symbol}: {data.get('lastPrice', 'N/A')}")
            else:
                logger.info(f"üìà Retrieved ticker data for {len(data) if isinstance(data, list) else 1} symbols")
            return data
        
        logger.warning(f"‚ö†Ô∏è No ticker data for {symbol or 'all symbols'}")
        return None
    
    def get_24h_ticker(self, symbol):
        """L·∫•y ticker 24h cho m·ªôt symbol c·ª• th·ªÉ"""
        return self.get_ticker(symbol)
    
    def get_funding_rate(self, symbol, start_time=None, end_time=None, limit=100):
        """L·∫•y funding rate (optional)"""
        endpoint = '/fapi/v1/fundingRate'
        params = {'symbol': symbol, 'limit': limit}
        
        if start_time:
            if isinstance(start_time, datetime):
                start_time = int(start_time.timestamp() * 1000)
            params['startTime'] = start_time
            
        if end_time:
            if isinstance(end_time, datetime):
                end_time = int(end_time.timestamp() * 1000)
            params['endTime'] = end_time
        
        return self._make_request(endpoint, params=params)
    
    # Helper methods
    def _get_interval_milliseconds(self, interval):
        """Chuy·ªÉn ƒë·ªïi interval string sang milliseconds"""
        interval_map = {
            '1m': 60 * 1000,
            '3m': 3 * 60 * 1000,
            '5m': 5 * 60 * 1000,
            '15m': 15 * 60 * 1000,
            '30m': 30 * 60 * 1000,
            '1h': 60 * 60 * 1000,
            '2h': 2 * 60 * 60 * 1000,
            '4h': 4 * 60 * 60 * 1000,
            '6h': 6 * 60 * 60 * 1000,
            '8h': 8 * 60 * 60 * 1000,
            '12h': 12 * 60 * 60 * 1000,
            '1d': 24 * 60 * 60 * 1000,
            '3d': 3 * 24 * 60 * 60 * 1000,
            '1w': 7 * 24 * 60 * 60 * 1000,
        }
        return interval_map.get(interval, 60 * 60 * 1000)
    
    def _process_klines_data(self, data):
        """X·ª≠ l√Ω d·ªØ li·ªáu klines th√†nh DataFrame"""
        if not data:
            return pd.DataFrame()
        
        df = pd.DataFrame(data, columns=[
            'open_time', 'open', 'high', 'low', 'close', 'volume',
            'close_time', 'quote_volume', 'trades_count', 
            'taker_buy_base_volume', 'taker_buy_quote_volume', 'ignore'
        ])
        
        if df.empty:
            return df
        
        # Convert data types
        numeric_cols = ['open', 'high', 'low', 'close', 'volume', 'quote_volume',
                       'taker_buy_base_volume', 'taker_buy_quote_volume', 'trades_count']
        
        for col in numeric_cols:
            df[col] = pd.to_numeric(df[col], errors='coerce')
        
        # Convert timestamps
        df['open_time'] = pd.to_datetime(df['open_time'], unit='ms')
        df['close_time'] = pd.to_datetime(df['close_time'], unit='ms')
        
        # Remove the ignore column
        df = df.drop('ignore', axis=1)
        
        # Log sample data ƒë·ªÉ debug
        if not df.empty:
            logger.info(f"üìä Sample volume: {df['volume'].iloc[0]}, Quote volume: {df['quote_volume'].iloc[0]}")
        
        return df
    
    def _process_oi_data(self, data):
        """X·ª≠ l√Ω d·ªØ li·ªáu Open Interest th√†nh DataFrame"""
        if not data:
            return pd.DataFrame()
        
        df = pd.DataFrame(data)
        
        if df.empty:
            return df
        
        # Convert data types
        if 'sumOpenInterest' in df.columns:
            # ƒê·∫£m b·∫£o ƒë∆°n v·ªã ch√≠nh x√°c - ƒë√¢y l√† gi√° tr·ªã g·ªëc, kh√¥ng c·∫ßn chia th√™m
            df['sumOpenInterest'] = pd.to_numeric(df['sumOpenInterest'], errors='coerce')
            # Log gi√° tr·ªã ƒë·ªÉ debug
            if not df.empty:
                logger.info(f"üìä Sample OI value: {df['sumOpenInterest'].iloc[0]}")
        
        if 'sumOpenInterestValue' in df.columns:
            # ƒê√¢y l√† gi√° tr·ªã theo USDT
            df['sumOpenInterestValue'] = pd.to_numeric(df['sumOpenInterestValue'], errors='coerce')
            # Log gi√° tr·ªã ƒë·ªÉ debug
            if not df.empty:
                logger.info(f"üí∞ Sample OI value (USDT): {df['sumOpenInterestValue'].iloc[0]}")
        
        # Convert timestamp
        if 'timestamp' in df.columns:
            df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')
        
        return df
    
    def test_connection(self):
        """Test k·∫øt n·ªëi API"""
        try:
            server_time = self.get_server_time(force_refresh=True)
            exchange_info = self.get_exchange_info()
            
            if server_time and exchange_info:
                logger.info("‚úÖ API connection test successful")
                return True
            else:
                logger.error("‚ùå API connection test failed")
                return False
                
        except Exception as e:
            logger.error(f"‚ùå API connection test error: {str(e)}")
            return False

# Backward compatibility
BinanceAPI = OptimizedBinanceAPI