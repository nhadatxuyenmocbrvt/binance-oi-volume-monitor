import pandas as pd
import numpy as np
from scipy import stats
from datetime import datetime, timedelta
from config.settings import setup_logging

logger = setup_logging(__name__, 'metrics.log')

class OptimizedOIVolumeMetrics:
    """
    L·ªõp t·ªëi ∆∞u cho vi·ªác t√≠nh to√°n metrics t·∫≠p trung v√†o OI & Volume
    Focus: 24h tracking (hourly) + 30d tracking (daily)
    """
    
    def __init__(self):
        logger.info("üîß Kh·ªüi t·∫°o OptimizedOIVolumeMetrics - Focus OI & Volume")
    
    # H√†m t√≠nh to√°n metrics cho OI (hourly)
    def calculate_hourly_oi_metrics(self, df):
        """T√≠nh to√°n c√°c metrics OI theo gi·ªù"""
        try:
            if df.empty:
                return self._get_empty_oi_metrics()
            
            # L·∫•y d·ªØ li·ªáu OI hi·ªán t·∫°i v√† 24h tr∆∞·ªõc
            current_oi = float(df['open_interest'].iloc[-1])
            previous_oi = float(df['open_interest'].iloc[0]) if len(df) > 1 else current_oi
            
            # T√≠nh thay ƒë·ªïi
            oi_change_24h = ((current_oi - previous_oi) / previous_oi * 100) if previous_oi != 0 else 0
            
            # T√≠nh c√°c metrics kh√°c
            max_oi = float(df['open_interest'].max())
            min_oi = float(df['open_interest'].min())
            avg_oi = float(df['open_interest'].mean())
            
            # T√≠nh volatility (ƒë·ªô bi·∫øn ƒë·ªông)
            if len(df) > 1:
                std_oi = float(df['open_interest'].std())
                volatility = (std_oi / avg_oi * 100) if avg_oi != 0 else 0
            else:
                volatility = 0
            
            # Th√™m log ƒë·ªÉ debug
            print(f"OI Data: current={current_oi}, previous={previous_oi}, change={oi_change_24h}%")
            
            return {
                'current_oi': current_oi,
                'previous_oi': previous_oi,
                'oi_change_24h': oi_change_24h,
                'max_oi': max_oi,
                'min_oi': min_oi,
                'avg_oi': avg_oi,
                'volatility': volatility,
                'data_points': len(df)
            }
            
        except Exception as e:
            print(f"Error calculating OI metrics: {e}")
            return self._get_empty_oi_metrics()

    # H√†m t√≠nh to√°n metrics cho Volume (hourly)
    def calculate_hourly_volume_metrics(self, df):
        """T√≠nh to√°n c√°c metrics Volume theo gi·ªù"""
        try:
            if df.empty:
                return self._get_empty_volume_metrics()
            
            # L·∫•y d·ªØ li·ªáu Volume hi·ªán t·∫°i v√† 24h tr∆∞·ªõc
            current_volume = float(df['volume'].iloc[-1])
            previous_volume = float(df['volume'].iloc[0]) if len(df) > 1 else current_volume
            
            # T√≠nh thay ƒë·ªïi
            volume_change_24h = ((current_volume - previous_volume) / previous_volume * 100) if previous_volume != 0 else 0
            
            # T√≠nh c√°c metrics kh√°c
            max_volume = float(df['volume'].max())
            min_volume = float(df['volume'].min())
            avg_volume = float(df['volume'].mean())
            
            # T√≠nh volatility (ƒë·ªô bi·∫øn ƒë·ªông)
            if len(df) > 1:
                std_volume = float(df['volume'].std())
                volatility = (std_volume / avg_volume * 100) if avg_volume != 0 else 0
            else:
                volatility = 0
                
            # Th√™m log ƒë·ªÉ debug
            print(f"Volume Data: current={current_volume}, previous={previous_volume}, change={volume_change_24h}%")
            
            return {
                'current_volume': current_volume,
                'previous_volume': previous_volume,
                'volume_change_24h': volume_change_24h,
                'max_volume': max_volume,
                'min_volume': min_volume,
                'avg_volume': avg_volume,
                'volatility': volatility,
                'data_points': len(df)
            }
            
        except Exception as e:
            print(f"Error calculating Volume metrics: {e}")
            return self._get_empty_volume_metrics()
    
    def calculate_daily_oi_metrics(self, df, days=30):
        """
        T√≠nh to√°n metrics OI theo ng√†y (30d focus)
        """
        try:
            if df.empty or len(df) < 2:
                logger.warning("Kh√¥ng ƒë·ªß d·ªØ li·ªáu ƒë·ªÉ t√≠nh OI metrics h√†ng ng√†y")
                return self._get_empty_oi_metrics_30d()
            
            # L·∫•y d·ªØ li·ªáu g·∫ßn nh·∫•t
            recent_df = df.tail(days) if len(df) > days else df
            recent_df = recent_df.copy()
            
            # S·ª≠ d·ª•ng c·ªôt ph√π h·ª£p (avg_open_interest cho daily_tracking)
            oi_column = 'avg_open_interest' if 'avg_open_interest' in recent_df.columns else 'open_interest'
            
            current_oi = recent_df[oi_column].iloc[-1]
            first_oi = recent_df[oi_column].iloc[0]
            
            # Thay ƒë·ªïi 30d
            oi_change_30d = ((current_oi - first_oi) / first_oi) * 100 if first_oi > 0 else 0
            
            # Thay ƒë·ªïi 7d (n·∫øu c√≥ ƒë·ªß d·ªØ li·ªáu)
            if len(recent_df) >= 7:
                oi_7d_ago = recent_df[oi_column].iloc[-7]
                oi_change_7d = ((current_oi - oi_7d_ago) / oi_7d_ago) * 100 if oi_7d_ago > 0 else 0
            else:
                oi_change_7d = 0
            
            # Daily changes
            recent_df['oi_daily_change'] = recent_df[oi_column].pct_change() * 100
            
            # Volatility v√† trend
            oi_daily_volatility = recent_df['oi_daily_change'].std()
            positive_days = (recent_df['oi_daily_change'] > 0).sum()
            negative_days = (recent_df['oi_daily_change'] < 0).sum()
            total_days = len(recent_df) - 1
            
            trend_direction = 'bullish' if positive_days > negative_days else ('bearish' if negative_days > positive_days else 'neutral')
            
            # Moving averages
            if len(recent_df) >= 7:
                recent_df['oi_ma7d'] = recent_df[oi_column].rolling(window=7).mean()
                oi_above_ma7d = current_oi > recent_df['oi_ma7d'].iloc[-1]
            else:
                oi_above_ma7d = None
            
            if len(recent_df) >= 14:
                recent_df['oi_ma14d'] = recent_df[oi_column].rolling(window=14).mean()
                oi_above_ma14d = current_oi > recent_df['oi_ma14d'].iloc[-1]
            else:
                oi_above_ma14d = None
            
            # Extremes
            max_oi = recent_df[oi_column].max()
            min_oi = recent_df[oi_column].min()
            avg_oi_30d = recent_df[oi_column].mean()
            
            metrics = {
                'current_oi': current_oi,
                'avg_oi_30d': round(avg_oi_30d, 2),
                'oi_change_30d': round(oi_change_30d, 4),
                'oi_change_7d': round(oi_change_7d, 4),
                'oi_daily_volatility': round(oi_daily_volatility, 4),
                'trend_direction': trend_direction,
                'positive_days': int(positive_days),
                'negative_days': int(negative_days),
                'oi_above_ma7d': oi_above_ma7d,
                'oi_above_ma14d': oi_above_ma14d,
                'max_oi_30d': max_oi,
                'min_oi_30d': min_oi,
                'oi_range_30d_pct': round(((max_oi - min_oi) / min_oi) * 100, 2) if min_oi > 0 else 0,
                'total_data_points': len(recent_df)
            }
            
            logger.info(f"‚úÖ T√≠nh to√°n OI metrics 30d: {trend_direction} {oi_change_30d:.2f}%")
            return metrics
            
        except Exception as e:
            logger.error(f"‚ùå L·ªói khi t√≠nh OI metrics h√†ng ng√†y: {str(e)}")
            return self._get_empty_oi_metrics_30d()
    
    def calculate_daily_volume_metrics(self, df, days=30):
        """
        T√≠nh to√°n metrics Volume theo ng√†y (30d focus)
        """
        try:
            if df.empty or len(df) < 2:
                logger.warning("Kh√¥ng ƒë·ªß d·ªØ li·ªáu ƒë·ªÉ t√≠nh Volume metrics h√†ng ng√†y")
                return self._get_empty_volume_metrics_30d()
            
            # L·∫•y d·ªØ li·ªáu g·∫ßn nh·∫•t
            recent_df = df.tail(days) if len(df) > days else df
            recent_df = recent_df.copy()
            
            # S·ª≠ d·ª•ng c·ªôt ph√π h·ª£p (total_volume cho daily_tracking)
            volume_column = 'total_volume' if 'total_volume' in recent_df.columns else 'volume'
            
            current_volume = recent_df[volume_column].iloc[-1]
            first_volume = recent_df[volume_column].iloc[0]
            
            # Thay ƒë·ªïi 30d
            volume_change_30d = ((current_volume - first_volume) / first_volume) * 100 if first_volume > 0 else 0
            
            # Thay ƒë·ªïi 7d
            if len(recent_df) >= 7:
                volume_7d_ago = recent_df[volume_column].iloc[-7]
                volume_change_7d = ((current_volume - volume_7d_ago) / volume_7d_ago) * 100 if volume_7d_ago > 0 else 0
            else:
                volume_change_7d = 0
            
            # Daily changes
            recent_df['volume_daily_change'] = recent_df[volume_column].pct_change() * 100
            
            # Volume metrics ƒë·∫∑c bi·ªát cho 30d
            total_volume_30d = recent_df[volume_column].sum()
            avg_volume_30d = recent_df[volume_column].mean()
            volume_daily_volatility = recent_df['volume_daily_change'].std()
            
            # Trend analysis
            positive_days = (recent_df['volume_daily_change'] > 0).sum()
            negative_days = (recent_df['volume_daily_change'] < 0).sum()
            total_days = len(recent_df) - 1
            
            trend_direction = 'increasing' if positive_days > negative_days else ('decreasing' if negative_days > positive_days else 'stable')
            
            # Volume distribution
            volume_std = recent_df[volume_column].std()
            volume_cv = (volume_std / avg_volume_30d) if avg_volume_30d > 0 else 0  # Coefficient of variation
            
            # High volume days
            high_volume_threshold = avg_volume_30d + volume_std
            high_volume_days = (recent_df[volume_column] > high_volume_threshold).sum()
            
            # Moving averages
            if len(recent_df) >= 7:
                recent_df['volume_ma7d'] = recent_df[volume_column].rolling(window=7).mean()
                volume_above_ma7d = current_volume > recent_df['volume_ma7d'].iloc[-1]
            else:
                volume_above_ma7d = None
            
            metrics = {
                'current_volume': current_volume,
                'avg_volume_30d': round(avg_volume_30d, 2),
                'total_volume_30d': total_volume_30d,
                'volume_change_30d': round(volume_change_30d, 4),
                'volume_change_7d': round(volume_change_7d, 4),
                'volume_daily_volatility': round(volume_daily_volatility, 4),
                'trend_direction': trend_direction,
                'positive_days': int(positive_days),
                'negative_days': int(negative_days),
                'volume_above_ma7d': volume_above_ma7d,
                'high_volume_days': int(high_volume_days),
                'volume_cv': round(volume_cv, 4),
                'max_volume_30d': recent_df[volume_column].max(),
                'min_volume_30d': recent_df[volume_column].min(),
                'total_data_points': len(recent_df)
            }
            
            logger.info(f"‚úÖ T√≠nh to√°n Volume metrics 30d: {trend_direction} {volume_change_30d:.2f}%")
            return metrics
            
        except Exception as e:
            logger.error(f"‚ùå L·ªói khi t√≠nh Volume metrics h√†ng ng√†y: {str(e)}")
            return self._get_empty_volume_metrics_30d()
    
    def calculate_oi_volume_correlation(self, df, period='24h'):
        """
        T√≠nh to√°n t∆∞∆°ng quan gi·ªØa OI v√† Volume
        """
        try:
            if df.empty or len(df) < 3:
                return {
                    'correlation': 0,
                    'correlation_strength': 'no_data',
                    'sample_size': 0
                }
            
            # Ch·ªçn c·ªôt ph√π h·ª£p
            if period == '24h':
                oi_col = 'open_interest'
                vol_col = 'volume'
            else:
                oi_col = 'avg_open_interest' if 'avg_open_interest' in df.columns else 'open_interest'
                vol_col = 'total_volume' if 'total_volume' in df.columns else 'volume'
            
            # T√≠nh correlation
            correlation = df[oi_col].corr(df[vol_col])
            
            if pd.isna(correlation):
                correlation = 0
            
            # Ph√¢n lo·∫°i m·ª©c ƒë·ªô t∆∞∆°ng quan
            if abs(correlation) >= 0.7:
                strength = 'strong'
            elif abs(correlation) >= 0.4:
                strength = 'moderate'
            elif abs(correlation) >= 0.2:
                strength = 'weak'
            else:
                strength = 'negligible'
            
            # Th√™m h∆∞·ªõng
            if correlation > 0:
                direction = 'positive'
            elif correlation < 0:
                direction = 'negative'
            else:
                direction = 'neutral'
            
            result = {
                'correlation': round(correlation, 4),
                'correlation_strength': f"{strength}_{direction}",
                'sample_size': len(df),
                'interpretation': self._interpret_correlation(correlation)
            }
            
            logger.info(f"üìä OI-Volume correlation ({period}): {correlation:.3f} ({strength})")
            return result
            
        except Exception as e:
            logger.error(f"‚ùå L·ªói khi t√≠nh correlation OI-Volume: {str(e)}")
            return {
                'correlation': 0,
                'correlation_strength': 'error',
                'sample_size': 0,
                'interpretation': 'Kh√¥ng th·ªÉ t√≠nh to√°n'
            }
    
    def detect_oi_volume_anomalies(self, df, threshold=2.5):
        """
        Ph√°t hi·ªán b·∫•t th∆∞·ªùng cho OI v√† Volume
        """
        try:
            anomalies = []
            
            if df.empty or len(df) < 10:
                return anomalies
            
            # Columns ƒë·ªÉ check
            columns_to_check = []
            if 'open_interest' in df.columns:
                columns_to_check.append(('open_interest', 'OI'))
            if 'volume' in df.columns:
                columns_to_check.append(('volume', 'Volume'))
            if 'avg_open_interest' in df.columns:
                columns_to_check.append(('avg_open_interest', 'OI_Daily'))
            if 'total_volume' in df.columns:
                columns_to_check.append(('total_volume', 'Volume_Daily'))
            
            for col, name in columns_to_check:
                # T√≠nh Z-score
                mean_val = df[col].mean()
                std_val = df[col].std()
                
                if std_val > 0:
                    z_scores = np.abs((df[col] - mean_val) / std_val)
                    anomaly_mask = z_scores > threshold
                    
                    if anomaly_mask.any():
                        anomaly_indices = df[anomaly_mask].index
                        for idx in anomaly_indices:
                            anomalies.append({
                                'timestamp': df.loc[idx, 'timestamp'] if 'timestamp' in df.columns else (
                                    df.loc[idx, 'hour_timestamp'] if 'hour_timestamp' in df.columns else (
                                        df.loc[idx, 'date'] if 'date' in df.columns else idx
                                    )
                                ),
                                'metric': name,
                                'value': df.loc[idx, col],
                                'z_score': z_scores.loc[idx],
                                'threshold': threshold,
                                'severity': 'high' if z_scores.loc[idx] > threshold + 1 else 'moderate'
                            })
            
            logger.info(f"üö® Ph√°t hi·ªán {len(anomalies)} anomalies v·ªõi threshold {threshold}")
            return anomalies
            
        except Exception as e:
            logger.error(f"‚ùå L·ªói khi ph√°t hi·ªán anomalies: {str(e)}")
            return []
    
    def generate_summary_metrics(self, oi_metrics_24h, volume_metrics_24h, oi_metrics_30d, volume_metrics_30d):
        """
        T·∫°o metrics t·ªïng h·ª£p
        """
        try:
            summary = {
                'timestamp': datetime.now().isoformat(),
                '24h_summary': {
                    'oi_trend': oi_metrics_24h.get('trend_direction', 'neutral'),
                    'oi_change': oi_metrics_24h.get('oi_change_24h', 0),
                    'volume_trend': volume_metrics_24h.get('trend_direction', 'stable'),
                    'volume_change': volume_metrics_24h.get('volume_change_24h', 0),
                    'overall_sentiment': self._determine_sentiment_24h(oi_metrics_24h, volume_metrics_24h)
                },
                '30d_summary': {
                    'oi_trend': oi_metrics_30d.get('trend_direction', 'neutral'),
                    'oi_change': oi_metrics_30d.get('oi_change_30d', 0),
                    'volume_trend': volume_metrics_30d.get('trend_direction', 'stable'),
                    'volume_change': volume_metrics_30d.get('volume_change_30d', 0),
                    'overall_sentiment': self._determine_sentiment_30d(oi_metrics_30d, volume_metrics_30d)
                },
                'data_quality': {
                    'oi_24h_points': oi_metrics_24h.get('total_data_points', 0),
                    'volume_24h_points': volume_metrics_24h.get('total_data_points', 0),
                    'oi_30d_points': oi_metrics_30d.get('total_data_points', 0),
                    'volume_30d_points': volume_metrics_30d.get('total_data_points', 0)
                }
            }
            
            return summary
            
        except Exception as e:
            logger.error(f"‚ùå L·ªói khi t·∫°o summary metrics: {str(e)}")
            return {}
    
    # Helper methods
    def _get_empty_oi_metrics(self):
        return {
            'current_oi': 0,
            'oi_change_24h': 0,
            'oi_volatility': 0,
            'trend_direction': 'neutral',
            'trend_strength': 0,
            'positive_hours': 0,
            'negative_hours': 0,
            'oi_above_ma6h': None,
            'oi_range_24h_pct': 0,
            'support_level': 0,
            'resistance_level': 0,
            'max_oi_24h': 0,
            'min_oi_24h': 0,
            'total_data_points': 0
        }
    
    def _get_empty_volume_metrics(self):
        return {
            'current_volume': 0,
            'volume_change_24h': 0,
            'total_volume_24h': 0,
            'avg_volume_24h': 0,
            'volume_volatility': 0,
            'trend_direction': 'stable',
            'volume_spikes': 0,
            'volume_concentration': 0,
            'volume_above_ma6h': None,
            'max_volume_24h': 0,
            'min_volume_24h': 0,
            'positive_hours': 0,
            'negative_hours': 0,
            'total_data_points': 0
        }
    
    def _get_empty_oi_metrics_30d(self):
        return {
            'current_oi': 0,
            'avg_oi_30d': 0,
            'oi_change_30d': 0,
            'oi_change_7d': 0,
            'oi_daily_volatility': 0,
            'trend_direction': 'neutral',
            'positive_days': 0,
            'negative_days': 0,
            'oi_above_ma7d': None,
            'oi_above_ma14d': None,
            'max_oi_30d': 0,
            'min_oi_30d': 0,
            'oi_range_30d_pct': 0,
            'total_data_points': 0
        }
    
    def _get_empty_volume_metrics_30d(self):
        return {
            'current_volume': 0,
            'avg_volume_30d': 0,
            'total_volume_30d': 0,
            'volume_change_30d': 0,
            'volume_change_7d': 0,
            'volume_daily_volatility': 0,
            'trend_direction': 'stable',
            'positive_days': 0,
            'negative_days': 0,
            'volume_above_ma7d': None,
            'high_volume_days': 0,
            'volume_cv': 0,
            'max_volume_30d': 0,
            'min_volume_30d': 0,
            'total_data_points': 0
        }
    
    def _interpret_correlation(self, correlation):
        if abs(correlation) >= 0.7:
            return "T∆∞∆°ng quan m·∫°nh - OI v√† Volume di chuy·ªÉn c√πng h∆∞·ªõng r√µ r·ªát"
        elif abs(correlation) >= 0.4:
            return "T∆∞∆°ng quan trung b√¨nh - C√≥ m·ªëi li√™n h·ªá ƒë√°ng ch√∫ √Ω"
        elif abs(correlation) >= 0.2:
            return "T∆∞∆°ng quan y·∫øu - M·ªëi li√™n h·ªá kh√¥ng r√µ r√†ng"
        else:
            return "Kh√¥ng c√≥ t∆∞∆°ng quan - OI v√† Volume di chuy·ªÉn ƒë·ªôc l·∫≠p"
    
    def _determine_sentiment_24h(self, oi_metrics, volume_metrics):
        oi_change = oi_metrics.get('oi_change_24h', 0)
        volume_change = volume_metrics.get('volume_change_24h', 0)
        
        if oi_change > 5 and volume_change > 20:
            return 'strong_bullish'
        elif oi_change > 1 and volume_change > 5:
            return 'bullish'
        elif oi_change < -5 and volume_change < -20:
            return 'strong_bearish'
        elif oi_change < -1 and volume_change < -5:
            return 'bearish'
        else:
            return 'neutral'
    
    def _determine_sentiment_30d(self, oi_metrics, volume_metrics):
        oi_change = oi_metrics.get('oi_change_30d', 0)
        volume_change = volume_metrics.get('volume_change_30d', 0)
        
        if oi_change > 20 and volume_change > 50:
            return 'strong_bullish'
        elif oi_change > 5 and volume_change > 15:
            return 'bullish'
        elif oi_change < -20 and volume_change < -50:
            return 'strong_bearish'
        elif oi_change < -5 and volume_change < -15:
            return 'bearish'
        else:
            return 'neutral'